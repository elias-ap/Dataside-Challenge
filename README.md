<div align="center">
<img src="https://static.wixstatic.com/media/efe4c3_d4c9a129e6264a75bbcc9f54ec63bd45~mv2.png/v1/fill/w_145,h_70,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/Dataside%20-%20Monocromatico.png">
</div>

<h1 align="center">Dataside Challenge</h1>

<p align="justify">O desafio que a Dataside propôs, foi o desenvolvimento de um notebook que será responsável por extrair 
  dados de previsão do tempo das cidades do Vale do Paraíba, região onde se localiza a <b>Dataside</b>.</p>

```geojson
{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {},
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              -45.531066947648696,
              -22.317476475215663
            ],
            [
              -45.604106939430295,
              -22.320779246240836
            ],
            [
              -45.6764539245122,
              -22.33065621825252
            ],
            [
              -45.74742118613727,
              -22.347013652935406
            ],
            [
              -45.81633454028571,
              -22.369696267177996
            ],
            [
              -45.882538484222,
              -22.398488646593886
            ],
            [
              -45.94540220379486,
              -22.433117209271963
            ],
            [
              -46.00432539266011,
              -22.47325270462371
            ],
            [
              -46.05874383685267,
              -22.518513227940257
            ],
            [
              -46.10813471850796,
              -22.568467727068608
            ],
            [
              -46.15202159306033,
              -22.622639973478407
            ],
            [
              -46.189978994975654,
              -22.68051296593275
            ],
            [
              -46.22163662806159,
              -22.741533731016354
            ],
            [
              -46.24668309770684,
              -22.805118480933665
            ],
            [
              -46.26486914410349,
              -22.870658085293773
            ],
            [
              -46.27601033767974,
              -22.93752381008088
            ],
            [
              -46.279989200694565,
              -23.00507327370694
            ],
            [
              -46.276756722296895,
              -23.07265656700337
            ],
            [
              -46.26633323839952,
              -23.139622481284647
            ],
            [
              -46.24880865251833,
              -23.20532478626976
            ],
            [
              -46.22434197931646,
              -23.26912849774367
            ],
            [
              -46.19316019898278,
              -23.33041607345235
            ],
            [
              -46.15555641774358,
              -23.388593474924484
            ],
            [
              -46.1118873377006,
              -23.44309603277202
            ],
            [
              -46.062570047712015,
              -23.493394053608533
            ],
            [
              -46.008078156051795,
              -23.53899810809604
            ],
            [
              -45.94893729492325,
              -23.57946394183328
            ],
            [
              -45.88572003635645,
              -23.61439695385931
            ],
            [
              -45.81904026835089,
              -23.64345619147295
            ],
            [
              -45.74954708907608,
              -23.666357814844808
            ],
            [
              -45.677918285253355,
              -23.682877990482858
            ],
            [
              -45.60485346824652,
              -23.692855178936473
            ],
            [
              -45.531066947648696,
              -23.696191789094797
            ],
            [
              -45.45728042705088,
              -23.692855178936473
            ],
            [
              -45.38421561004404,
              -23.682877990482858
            ],
            [
              -45.312586806221304,
              -23.666357814844815
            ],
            [
              -45.243093626946504,
              -23.64345619147295
            ],
            [
              -45.176413858940926,
              -23.61439695385931
            ],
            [
              -45.113196600374145,
              -23.57946394183328
            ],
            [
              -45.054055739245584,
              -23.53899810809604
            ],
            [
              -44.999563847585364,
              -23.493394053608533
            ],
            [
              -44.95024655759679,
              -23.44309603277202
            ],
            [
              -44.9065774775538,
              -23.388593474924484
            ],
            [
              -44.868973696314605,
              -23.33041607345235
            ],
            [
              -44.83779191598093,
              -23.26912849774367
            ],
            [
              -44.813325242779065,
              -23.20532478626976
            ],
            [
              -44.79580065689787,
              -23.13962248128465
            ],
            [
              -44.7853771730005,
              -23.07265656700337
            ],
            [
              -44.78214469460281,
              -23.00507327370694
            ],
            [
              -44.78612355761764,
              -22.93752381008088
            ],
            [
              -44.7972647511939,
              -22.870658085293773
            ],
            [
              -44.81545079759054,
              -22.805118480933665
            ],
            [
              -44.840497267235804,
              -22.741533731016354
            ],
            [
              -44.87215490032173,
              -22.68051296593275
            ],
            [
              -44.91011230223706,
              -22.622639973478407
            ],
            [
              -44.953999176789424,
              -22.568467727068608
            ],
            [
              -45.003390058444715,
              -22.518513227940257
            ],
            [
              -45.057808502637286,
              -22.47325270462371
            ],
            [
              -45.116731691502515,
              -22.433117209271963
            ],
            [
              -45.17959541107539,
              -22.398488646593886
            ],
            [
              -45.24579935501167,
              -22.369696267177996
            ],
            [
              -45.31471270916011,
              -22.347013652935406
            ],
            [
              -45.385679970785176,
              -22.33065621825252
            ],
            [
              -45.45802695586708,
              -22.320779246240836
            ],
            [
              -45.531066947648696,
              -22.317476475215663
            ]
          ]
        ]
      }
    }
  ]
}
```

<p align="justify">Ao final da consulta, exportar dados selecionados para formato de arquivo .CSV, separando os em duas tabelas com os seguintes campos:</p>

### Tabela 1
Cidade |	CodigoDaCidade | Regiao |	Data | Pais |	Latitude	| Longitude	| TemperaturaMaxima	| TemperaturaMinima	| TemperaturaMedia	| VaiChover	| ChanceDeChuva	| CondicaoDoTempo | NascerDoSol	| PorDoSol	| VelocidadeMaximaDoVento |
| ---- | --------------- | ------ | ---- | ---- | --------- | --------- | ----------------- | ----------------- | ----------------- | --------- | ------------- | -------------------- | ----------- | --------- | ----------------------- |

### Tabela 2
| Cidade |	QtdDiasVaiChover |	QtdDiasNaoVaiChover |	TotalDiasMapeados |
| ------ | ----------------- | -------------------- | ----------------- |

### Detalhes
Mais detalhes técnicos sobre o desafio podem ser encontrados no arquivo abaixo, juntamente com o código do notebook:
> [main.ipynb](https://github.com/elias-ap/Dataside-Challenge/blob/main/main.ipynb)

## Passos

1. Consultar todas as cidades dessa região utilizando uma API para localização das cidades:

```Python
# Buscar cidades do Vale do Paraíba
request = requests.get("https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios")
cities_info_dict = request.json()
```

2. Gerar um dataframe das cidade consultadas com os campos ID da cidade, nome da cidade e região:

```Python
# Criar data frame com as cidades
row_list = []
for city in cities_info_dict:
    row = {'ID_CITY': city['id'], 'CITY_NAME': city['nome'], 'CITY_REGION': city['microrregiao']['mesorregiao']['UF']['regiao']['nome']}
    row_list.append(row)
    
df_cities = spark.createDataFrame(row_list, schema='ID_CITY int, CITY_NAME string, CITY_REGION string')
```

3. Criar uma view temporária do dataframe gerado com as informações das cidades:

```Python
# Criar view com as cidades
df_cities.createOrReplaceTempView('CITIES')
```

4. Consultar dados geográficos (latitude e longitude) de cada cidade a partir da view das cidades utilizando uma API com essa funcionalidade:

```Python
# Buscar previsão do tempo para as cidades
translate_map = str.maketrans({'é': 'e', 'í': 'i', 'á': 'a', 'ç': 'c', 'ã': 'a', 'ô': 'o'})
row_list = []
for city in df_cities.collect():
    # API para buscar as coordenadas geográficas (latitude e longitude)
    geographic_coordinates_API = f"https://nominatim.openstreetmap.org/search?city={city['CITY_NAME']}&state=SP&country=BR&format=json"

    # Solicita os dados geográficos
    request = requests.get(geographic_coordinates_API)
    request_dict = request.json()

    latitude = request_dict[0]['lat']
    longitude = request_dict[0]['lon']
```

5. Com as coordenadas geográficas, consultar a previsão do tempo de cada cidade para os próximos 5 dias:

````Python
    # API para previsão do tempo
    forecast_weather_API = f"http://api.weatherapi.com/v1/forecast.json?key=c499600de8e14cb6804160909230701&q={latitude},{longitude}&days={days}&aqi=no&alerts=no&lang=pt"

    # Solicita dados de previsão do tempo da cidade
    request = requests.get(forecast_weather_API)
    forecast_request_dict = request.json()
    
    for d in range(0, days):
        forecast_day_dict = forecast_request_dict['forecast']['forecastday'][d]
        location_dict = forecast_request_dict['location']
        
        # Formatação de datas e horários
        date = datetime.fromisoformat(forecast_day_dict['date']).date()
        sunrise_time = datetime.strptime((forecast_day_dict['date'] + forecast_day_dict['astro']['sunrise']), '%Y-%m-%d%I:%M %p')
        sunset_time = datetime.strptime((forecast_day_dict['date'] + forecast_day_dict['astro']['sunset']), '%Y-%m-%d%I:%M %p')

        # Linha do registro de previsão do tempo
        row = {'Cidade': city['CITY_NAME'].translate(translate_map),
               'CodigoDaCidade': city['ID_CITY'],
               'Regiao': city['CITY_REGION'],
               'Data': date,
               'Pais': location_dict['country'],
               'Latitude': float(latitude),
               'Longitude': float(longitude),
               'TemperaturaMaxima': round(forecast_day_dict['day']['maxtemp_c']),
               'TemperaturaMinima': round(forecast_day_dict['day']['mintemp_c']),
               'TemperaturaMedia': round(forecast_day_dict['day']['avgtemp_c']),
               'VaiChover': forecast_day_dict['day']['daily_will_it_rain'],
               'ChanceDeChuva': forecast_day_dict['day']['daily_chance_of_rain'],
               'CondicaoDoTempo': forecast_day_dict['day']['condition']['text'],
               'NascerDoSol': sunrise_time,
               'PorDoSol': sunset_time,
               'VelocidadeMaximaDoVento': forecast_day_dict['day']['maxwind_mph']}

        row_list.append(row)
````

6. Gerar um dataframe das previsões consultadas com os campos ID da cidade, nome, região, data consultada, país, latitude, longitude, temperatua máxima, temperatura mínima, temperatura média, vai chover, chance de chuva, condição do tempo, nascer do sol, pôr do sol e velocidade máxima do vento:

```Python
# Criar data frame com as previsões
df_forecast = spark.createDataFrame(row_list, schema='Cidade string, CodigoDaCidade int, Regiao string,\
                                                      Data date, Pais string, Latitude float, Longitude float,\
                                                      TemperaturaMaxima int, TemperaturaMinima int, TemperaturaMedia int,\
                                                      VaiChover int, ChanceDeChuva int, CondicaoDoTempo string,\
                                                      NascerDoSol timestamp, PorDoSol timestamp, VelocidadeMaximaDoVento float')
```

7. Criar uma view temporária do dataframe gerado com as previsões:

```Python
# Criar view com as previsões
df_forecast.createOrReplaceTempView('FORECASTS')
```

8. Gerar um dataframe da Tabela 1 e 2, a partir da view das previsões:

```Python
# Criar DF da Tabela 1
df_table1 = spark.sql(f'SELECT Cidade, CodigoDaCidade, Regiao, Data,\
                       Pais, Latitude, Longitude, TemperaturaMaxima,\
                       TemperaturaMinima, TemperaturaMedia,\
                       case VaiChover WHEN 1 THEN "Sim" WHEN 0 THEN "Não" END VaiChover,\
                       ChanceDeChuva,\
                       CondicaoDoTempo,\
                       date_format(NascerDoSol, "HH:mm:ss") NascerDoSol,\
                       date_format(PorDoSol, "HH:mm:ss") PorDoSol,\
                       VelocidadeMaximaDoVento\
                       FROM FORECASTS\
                       WHERE Data BETWEEN "{initial_date}" AND "{end_date}"')

# Criar DF da Tabela 2
df_table2 = spark.sql(f'SELECT Cidade, \
                       COUNT(CASE VaiChover WHEN 1 THEN 1 END) AS QtdDiasVaiChover, \
                       COUNT(CASE VaiChover WHEN 0 THEN 1 END) AS QtdDiasNaoVaiChover, \
                       COUNT(Data) AS TotalDiasMapeados \
                       FROM FORECASTS \
                       WHERE Data BETWEEN "{initial_date}" AND "{end_date}" \
                       GROUP BY Cidade')

```

9. Exportar o data frame para formato .CSV:

```Python
# Exportar CSVs
df_table1.write.option('header', True).csv(r"C:\Tabela1", mode='overwrite')
df_table2.write.option('header', True).csv(r"C:\Tabela2", mode='overwrite')
```

Obs.: Para definifição das datas e dias a serem consultados foi utilizado o código abaixo:
```Python
# Seleciona a data incial (dia atual) e data final (5 dias após o dia atual)
initial_date = datetime.today().date()
end_date  = initial_date + timedelta(days=6)
days = abs(initial_date - end_date).days
```

Dessa forma, seria possível automatizar o software para sempre consultar os proximos 5 dias ou ainda controlar a saída de dados buscando por dias específicos.

## Output

> [Tabela 1](https://github.com/elias-ap/Dataside-Challenge/blob/main/Tabelas/Tabela1.csv)

> [Tabela 2](https://github.com/elias-ap/Dataside-Challenge/blob/main/Tabelas/Tabela2.csv)

## Tecnologias usadas

- Linguagens:
    - Python e SQL

- Bibliotecas:

    ```Python
    import findspark
    import requests
    import json
    import unidecode
    from datetime import datetime, timedelta
    from pyspark.sql import SparkSession
    from pyspark.sql.functions import to_date, current_date
    ```

- API's:
    - [Documentação API IBGE — Localidades](https://servicodados.ibge.gov.br/api/docs/localidades)
    - [Documentação API Nominatim — Dados geográficos](https://nominatim.org/release-docs/develop/api/Overview/)
    - [Documentação API Weather — Previsão do tempo](https://www.weatherapi.com/docs/)

---

<div align="center">
  <img height="100" width="100" align="center" src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/1869px-Python-logo-notext.svg.png"></img>
  <img height="100" width="150" align="center" src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1200px-Apache_Spark_logo.svg.png"></img>
  <img height="100" width="180" align="center" src="https://blog.weatherapi.com/wp-content/uploads/2020/02/cropped-Asset-62-1.png"></img>
  <img height="70" width="220" align="center" src="https://logodownload.org/wp-content/uploads/2018/02/ibge-logo.png"></img>
</div>
